{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q389WF40qHyN"
   },
   "source": [
    "# DATA SCIENCE INTERN @BHARAT INTERN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz3ognMOqMyW"
   },
   "source": [
    "### AUTHOR : PARVEJ ALAM M. ANSARI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX33eogTqW4x"
   },
   "source": [
    "## TASK 3 : MNIST Handwritten Digits Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC7vWZ3_lPJT"
   },
   "source": [
    "## Purpose: MNIST Handwritten Digits Recognition using Convolution Neural Network (CNN):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygi-1ywZlyD7"
   },
   "source": [
    "- Applying a Convolutional Neural Network (CNN) on the MNIST dataset is a popular way to learn about and demonstrate the capabilities of CNNs for image classification tasks. The MNIST dataset consists of 28×28 grayscale images of hand-written digits (0-9), with a training set of 60,000 examples and a test set of 10,000 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LU2zqmeFl_K6"
   },
   "source": [
    "Here is a basic approach to applying a CNN on the MNIST dataset using the Python programming language and the Keras library:\n",
    "\n",
    "    1. Load and preprocess the data: The MNIST dataset can be loaded using the Keras library, and the images can be normalized to have pixel values between 0 and 1.\n",
    "    2. Define the model architecture: The CNN can be constructed using the Keras Sequential API, which allows for easy building of sequential models layer-by-layer. The architecture should typically include convolutional layers, pooling layers, and fully-connected layers.\n",
    "    3. Compile the model: The model needs to be compiled with a loss function, an optimizer, and a metric for evaluation.\n",
    "    4. Train the model: The model can be trained on the training set using the Keras fit() function. It is important to monitor the training accuracy and loss to ensure the model is converging properly.\n",
    "    5. Evaluate the model: The trained model can be evaluated on the test set using the Keras evaluate() function. The evaluation metric typically used for classification tasks is accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MFDZn71mT0w"
   },
   "source": [
    "## References:\n",
    "\n",
    "    1. MNIST dataset: http://yann.lecun.com/exdb/mnist/\n",
    "    2. Keras documentation: https://keras.io/\n",
    "    3. “Deep Learning with Python” by Francois Chollet (https://www.manning.com/books/deep-learning-with-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1Hhmb-jmhLN"
   },
   "source": [
    "### 1. Importing all necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gdI-_PIylbCX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMtuMn4Rm9d0"
   },
   "source": [
    "### 2. Create the train data and test data:\n",
    "\n",
    "    - Test data: Used for testing the model that how our model has been trained.\n",
    "    - Train data: Used to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QD4c-6GemzcM"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuIJqLU9nSg9"
   },
   "source": [
    "- While proceeding further, img_rows and img_cols are used as the image dimensions. In mnist dataset, it is 28 and 28. We also need to check the data format i.e. ‘channels_first’ or ‘channels_last’. In CNN, we can normalize data before hands such that large terms of the calculations can be reduced to smaller terms. Like, we can normalize the x_train and x_test data by dividing it by 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mh-BSosBnezN"
   },
   "source": [
    "### 3. Checking data-format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1jCNeGXBnNWp"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols=28, 28\n",
    "\n",
    "if k.image_data_format() == 'channels_first':\n",
    "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "  inpx = (1, img_rows, img_cols)\n",
    "\n",
    "else:\n",
    "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "  inpx = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gosfRwd0n3pB"
   },
   "source": [
    "Description of the output classes:\n",
    "\n",
    "- Since the output of the model can comprise any of the digits between 0 to 9. so, we need 10 classes in output. To make output for 10 classes, use keras.utils.to_categorical function, which will provide the 10 columns. Out of these 10 columns, only one value will be one and the rest 9 will be zero and this one value of the output will denote the class of the digit.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TfWMEPT7n9GA"
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJV5Y0bnoNgb"
   },
   "source": [
    "### 4. CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PC6jcmXCoKBd"
   },
   "outputs": [],
   "source": [
    "inpx = Input(shape=inpx)\n",
    "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx)\n",
    "layer2 = Conv2D(64, (3, 3), activation='relu')(layer1)\n",
    "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
    "layer4 = Dropout(0.5)(layer3)\n",
    "layer5 = Flatten()(layer4)\n",
    "layer6 = Dense(250, activation='sigmoid')(layer5)\n",
    "layer7 = Dense(10, activation='softmax')(layer6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_izOpsHNoZbS"
   },
   "source": [
    "#### Explanation of the working of each layer in the CNN model:\n",
    "- layer1 is the Conv2d layer which convolves the image using 32 filters each of size (3*3).\n",
    "- layer2 is again a Conv2D layer which is also used to convolve the image and is using 64 filters each of size (3*3).\n",
    "- layer3 is the MaxPooling2D layer which picks the max value out of a matrix of size (3*3).\n",
    "- layer4 is showing Dropout at a rate of 0.5.\n",
    "- layer5 is flattening the output obtained from layer4 and this flattens output is passed to layer6.\n",
    "- layer6 is a hidden layer of a neural network containing 250 neurons.\n",
    "- layer7 is the output layer having 10 neurons for 10 classes of output that is using the softmax function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_zPfBr7ormc"
   },
   "source": [
    "### 5. Calling compile and fit function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oX00ZYRXoUwE",
    "outputId": "fbf160dd-d8a7-4b44-80a4-13edfb2bf30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "120/120 [==============================] - 8s 24ms/step - loss: 2.5728 - accuracy: 0.0987\n",
      "Epoch 2/12\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 2.5471 - accuracy: 0.0987\n",
      "Epoch 3/12\n",
      "120/120 [==============================] - 2s 21ms/step - loss: 2.5221 - accuracy: 0.0987\n",
      "Epoch 4/12\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 2.4974 - accuracy: 0.0987\n",
      "Epoch 5/12\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 2.4734 - accuracy: 0.0987\n",
      "Epoch 6/12\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 2.4499 - accuracy: 0.0987\n",
      "Epoch 7/12\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 2.4273 - accuracy: 0.0987\n",
      "Epoch 8/12\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 2.4055 - accuracy: 0.0987\n",
      "Epoch 9/12\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 2.3848 - accuracy: 0.0987\n",
      "Epoch 10/12\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 2.3647 - accuracy: 0.0987\n",
      "Epoch 11/12\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 2.3459 - accuracy: 0.0987\n",
      "Epoch 12/12\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 2.3284 - accuracy: 0.0987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7a08ecd2f100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([inpx], layer7)\n",
    "model.compile(optimizer=keras.optimizers.Adadelta(),\n",
    "\t\t\tloss=keras.losses.categorical_crossentropy,\n",
    "\t\t\tmetrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=12, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKtTjfz5pNuX"
   },
   "source": [
    "- Firstly, we made an object of the model as shown in the above-given lines, where [inpx] is the input in the model and layer7 is the output of the model.\n",
    "- We compiled the model using the required optimizer, loss function and printed the accuracy and at the last model.fit was called along with parameters like x_train(means image vectors), y_train(means the label), number of epochs, and the batch size.\n",
    "- Using fit function x_train, y_train dataset is fed to model in particular batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzEFORQWpmTK"
   },
   "source": [
    "### 6. Evaluation Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmN9CnDMpfB6"
   },
   "source": [
    "- model.evaluate provides the score for the test data i.e. provided the test data to the model. Now, the model will predict the class of the data, and the predicted class will be matched with the y_test label to give us the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZPWT0rapFxI",
    "outputId": "46e67de8-3f0d-47c4-f29e-d32b65f7485b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 2.3139891624450684\n",
      "accuracy= 0.09799999743700027\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86V5ZBMmpwE2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
